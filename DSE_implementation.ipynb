{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSE implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpT1NjRvYTw6",
        "colab_type": "code",
        "outputId": "0edd830c-4523-402d-97ee-8de5fd9e15e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "pip install PyPDF2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyPDF2\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=52005b07029d2d0aa85f7e8191d73fc78cb1eedf88bf88ac7480c1e14b064445\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "Successfully built PyPDF2\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQUie0ulYcfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ed802083-5532-4e89-f56a-7bbe7e54dc25"
      },
      "source": [
        "import PyPDF2\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import operator\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import os\n",
        "nltk.download('punkt')\n",
        "import collections\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh_8AJSMYFqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data ={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKVpHnPUGSpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entries_1 =[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TKDHmhd-XdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "entries = os.listdir('/content/drive/My Drive/PDF files ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP63Z-jaYvi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in range(len(entries)):\n",
        "  entries_1.append(\"/content/drive/My Drive/PDF files /\"+entries[f])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q24R50-CkKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_data = {}\n",
        "x =0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hmUj8fOAFHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "6704a20c-6eee-44c7-aea3-fa7211086a7a"
      },
      "source": [
        "for f in entries_1:\n",
        "  mypdf = open(f, mode='rb')\n",
        "  pdf_document = PyPDF2.PdfFileReader(mypdf)\n",
        "  first_page = pdf_document.getPage(0)\n",
        "  page = first_page.extractText()\n",
        "  tokens = word_tokenize(page)\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  words = [w for w in words if not w in alpha]\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  ans = \" \".join(words)\n",
        "  doc_data[entries[x]] = ans\n",
        "  x = x+1\n",
        "  if x%50 == 0:\n",
        "    print(x)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n",
            "100\n",
            "150\n",
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdCeQYMeB0eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del doc_data['Natural Language Processing with TensorFlow ( PDFDrive.com )-91.pdf'] \n",
        "del doc_data['Natural Language Processing with TensorFlow ( PDFDrive.com )-51.pdf'] \n",
        "del doc_data['Natural Language Processing with TensorFlow ( PDFDrive.com )-253.pdf'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAIoB5CPKqOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data =[]\n",
        "for m,n in doc_data.items():\n",
        "  file_string = nltk.word_tokenize(n)\n",
        "  train_data.extend(file_string)\n",
        "  #print(m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_sBwQUMHBPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 5000\n",
        "\n",
        "def build_dataset(words):\n",
        "  # Allocate a special token for rare words\n",
        "  count = [['UNK', -1]]\n",
        "\n",
        "  # Gets only the vocabulary_size most common words as the vocabulary\n",
        "  # All the other words will be replaced with UNK token\n",
        "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
        "\n",
        "\n",
        "  # Create an ID for each word by giving the current length of the dictionary\n",
        "  # And adding that item to the dictionary\n",
        "  dictionary = dict()\n",
        "  for word, _ in count:\n",
        "    dictionary[word] = len(dictionary)\n",
        "    \n",
        "  data = list()\n",
        "  unk_count = 0\n",
        "    \n",
        "  # Traverse through all the text we have and produce a list\n",
        "  # where each element corresponds to the ID of the word found at that index\n",
        "  for word in words:\n",
        "    # If word is in the dictionary use the word ID,\n",
        "    # else use the ID of the special token \"UNK\"\n",
        "    if word in dictionary:\n",
        "      index = dictionary[word]\n",
        "    else:\n",
        "      index = 0  # dictionary['UNK']\n",
        "      unk_count = unk_count + 1\n",
        "    data.append(index)\n",
        "  \n",
        "  # update the count variable with the number of UNK occurences\n",
        "  count[0][1] = unk_count\n",
        "    \n",
        "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
        "  # Make sure the dictionary is of size of the vocabulary\n",
        "  assert len(dictionary) == vocabulary_size\n",
        "\n",
        "  return data, count, dictionary, reverse_dictionary\n",
        "\n",
        "def build_dataset_with_existing_dictionary(words, dictionary):\n",
        "    '''\n",
        "    Here we use this function to convert word strings to IDs\n",
        "    with a given dictionary\n",
        "    '''\n",
        "    data = list()\n",
        "    for word in words:\n",
        "        if word in dictionary:\n",
        "          index = dictionary[word]\n",
        "        else:\n",
        "          index = 0  # dictionary['UNK']\n",
        "        data.append(index)\n",
        "    return data\n",
        "\n",
        "# Processining training data\n",
        "data, count, dictionary, reverse_dictionary = build_dataset(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryvgWFgzIv6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "93977387-72ed-4e5b-96e5-918e953ae25b"
      },
      "source": [
        "print('Most common words (+UNK)', count[:5])\n",
        "print('Sample data', data[:10])"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common words (+UNK) [['UNK', 54], ('word', 334), ('example', 244), ('words', 212), ('data', 209)]\n",
            "Sample data [6, 17, 569, 2567, 1382, 80, 6, 1100, 712, 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOM5A9WWIwIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wordsunique = set(train_data)\n",
        "wordsunique = list(wordsunique)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lIR8c2SsmrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "worddic={}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrS-OFTuqgEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for doc_name,doc_content in doc_data.items():\n",
        "  for word_1 in wordsunique:\n",
        "    if word_1 in doc_content:\n",
        "      index = doc_name\n",
        "   #   position = list(np.where(np.array(doc_data[index]) == word_1))\n",
        "    #  idfs = tfidf(word_1,doc_content,plottest)\n",
        "      try:\n",
        "        worddic[word_1].append([index])\n",
        "      except:\n",
        "        worddic[word_1] = []\n",
        "        worddic[word_1].append([index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m313_-vuslIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('worddic_10000.npy', worddic)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkAhPUtKoJNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"dictionary.npy\",dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZqE3TDEdbA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "df1 = pd.read_csv(\"/content/document_embeddings.csv\")\n",
        "document_embeddings1 = df1.to_dict('list')\n",
        "word_embedding1 = np.load('/content/word_embedding.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmERcHYXcyh2",
        "colab_type": "text"
      },
      "source": [
        "You can directly use above trained word and document embedding "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFBow1AkuGl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dataset_with_existing_dictionary(words, dictionary):\n",
        "    '''\n",
        "    Here we use this function to convert word strings to IDs\n",
        "    with a given dictionary\n",
        "    '''\n",
        "    words1 = words.split()\n",
        "    data = list()\n",
        "    for word in words1:\n",
        "        if word in dictionary:\n",
        "          index = dictionary[word]\n",
        "        else:\n",
        "          index = 0  # dictionary['UNK']\n",
        "        data.append(index)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6FfVUW_swA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = {}\n",
        "for k,v in doc_data.items():\n",
        "  #  print('Building Test Dataset for ',k,' topic')\n",
        "    test_data[k] = build_dataset_with_existing_dictionary(doc_data[k],dictionary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7phuP31yuzSz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "1665a48f-569d-4bba-cd4b-d8dac86b3d88"
      },
      "source": [
        "data_index = 0\n",
        "\n",
        "def generate_batch_cbow(batch_size, window_size):\n",
        "    # window_size is the amount of words we're looking at from each side of a given word\n",
        "    # creates a single batch\n",
        "    \n",
        "    # data_index is updated by 1 everytime we read a set of data point\n",
        "    global data_index\n",
        "\n",
        "    # span defines the total window size, where\n",
        "    # data we consider at an instance looks as follows. \n",
        "    # [ skip_window target skip_window ]\n",
        "    # e.g if skip_window = 2 then span = 5\n",
        "    span = 2 * window_size + 1 # [ skip_window target skip_window ]\n",
        "\n",
        "    # two numpy arras to hold target words (batch)\n",
        "    # and context words (labels)\n",
        "    # Note that batch has span-1=2*window_size columns\n",
        "    batch = np.ndarray(shape=(batch_size,span-1), dtype=np.int32)\n",
        "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
        "    \n",
        "    # The buffer holds the data contained within the span\n",
        "    buffer = collections.deque(maxlen=span)\n",
        "\n",
        "    # Fill the buffer and update the data_index\n",
        "    for _ in range(span):\n",
        "        buffer.append(data[data_index])\n",
        "        data_index = (data_index + 1) % len(data)\n",
        "\n",
        "    # Here we do the batch reading\n",
        "    # We iterate through each batch index\n",
        "    # For each batch index, we iterate through span elements\n",
        "    # to fill in the columns of batch array\n",
        "    for i in range(batch_size):\n",
        "        target = window_size  # target label at the center of the buffer\n",
        "        target_to_avoid = [ window_size ] # we only need to know the words around a given word, not the word itself\n",
        "\n",
        "        # add selected target to avoid_list for next time\n",
        "        col_idx = 0\n",
        "        for j in range(span):\n",
        "            # ignore the target word when creating the batch\n",
        "            if j==span//2:\n",
        "                continue\n",
        "            batch[i,col_idx] = buffer[j] \n",
        "            col_idx += 1\n",
        "        labels[i, 0] = buffer[target]\n",
        "\n",
        "        # Everytime we read a data point,\n",
        "        # we need to move the span by 1\n",
        "        # to create a fresh new span\n",
        "        buffer.append(data[data_index])\n",
        "        data_index = (data_index + 1) % len(data)\n",
        "\n",
        "    return batch, labels\n",
        "\n",
        "for window_size in [1,2]:\n",
        "    data_index = 0\n",
        "    batch, labels = generate_batch_cbow(batch_size=8, window_size=window_size)\n",
        "    print('\\nwith window_size = %d:' % (window_size))\n",
        "    print('    batch:', [[reverse_dictionary[bii] for bii in bi] for bi in batch])\n",
        "    print('    labels:', [reverse_dictionary[li] for li in labels.reshape(8)])\n"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "with window_size = 1:\n",
            "    batch: [['lstm', 'seen'], ['lstms', 'fancier'], ['seen', 'family'], ['fancier', 'rnns'], ['family', 'lstm'], ['rnns', 'composed'], ['lstm', 'mainly'], ['composed', 'cell']]\n",
            "    labels: ['lstms', 'seen', 'fancier', 'family', 'rnns', 'lstm', 'composed', 'mainly']\n",
            "\n",
            "with window_size = 2:\n",
            "    batch: [['lstm', 'lstms', 'fancier', 'family'], ['lstms', 'seen', 'family', 'rnns'], ['seen', 'fancier', 'rnns', 'lstm'], ['fancier', 'family', 'lstm', 'composed'], ['family', 'rnns', 'composed', 'mainly'], ['rnns', 'lstm', 'mainly', 'cell'], ['lstm', 'composed', 'cell', 'state'], ['composed', 'mainly', 'state', 'internal']]\n",
            "    labels: ['seen', 'fancier', 'family', 'rnns', 'lstm', 'composed', 'mainly', 'cell']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHpMBMZ02GDs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "6bb06fb9-3337-434e-eb59-7a8be71c28a0"
      },
      "source": [
        "test_data_index = 0\n",
        "\n",
        "def generate_test_batch(data, batch_size1):\n",
        "    '''\n",
        "    Generate a batch of data from the test data\n",
        "    This is used to compute the document embedding\n",
        "    by taking the average of all the words in a document\n",
        "    '''\n",
        "    global test_data_index\n",
        "\n",
        "    batch = np.ndarray(shape=(batch_size1,), dtype=np.int32)\n",
        "    # Get words starting from index 0 to span\n",
        "    for bi in range(batch_size1):\n",
        "        batch[bi] = data[test_data_index]\n",
        "        test_data_index = (test_data_index + 1) % len(data)\n",
        "\n",
        "    return batch\n",
        "\n",
        "test_data_index = 0\n",
        "test_batch = generate_test_batch(test_data[\"Natural Language Processing with TensorFlow ( PDFDrive.com )-248.pdf\"], 128)\n",
        "print('\\nwith window_size = %d:' % (window_size))\n",
        "print('    labels:', [reverse_dictionary[li] for li in test_batch.reshape(128)])"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "with window_size = 2:\n",
            "    labels: ['peephole', 'connectionspeephole', 'connections', 'allow', 'gates', 'see', 'current', 'input', 'previous', 'weights', 'lstm', 'cell', 'connections', 'shown', 'produce', 'better', 'results', 'equations', 'would', 'look', 'like', 'ihti', 'ct', 'iiw', 'xw', 'hw', 'cb', 'chtc', 'ct', 'anhwx', 'wh', 'fhtf', 'ct', 'ffw', 'xw', 'hw', 'cb', 'tt', 'tcf', 'ci', 'ohto', 'ct', 'oow', 'xw', 'hw', 'cb', 'tt', 'tho', 'tanhclook', 'helps', 'lstm', 'perform', 'better', 'far', 'gates', 'see', 'close', 'zero', 'thus', 'gates', 'take', 'hidden', 'state', 'consideration', 'calculation', 'including', 'cell', 'state', 'directly', 'gate', 'calculation', 'equation', 'allows', 'control', 'cell', 'state', 'perform', 'well', 'even', 'situations', 'output', 'gate', 'close', 'zero', 'peephole', 'connectionspeephole', 'connections', 'allow', 'gates', 'see', 'current', 'input', 'previous', 'weights', 'lstm', 'cell', 'connections', 'shown', 'produce', 'better', 'results', 'equations', 'would', 'look', 'like', 'ihti', 'ct', 'iiw', 'xw', 'hw', 'cb', 'chtc', 'ct', 'anhwx', 'wh', 'fhtf', 'ct', 'ffw', 'xw', 'hw', 'cb', 'tt', 'tcf', 'ci', 'ohto', 'ct', 'oow', 'xw']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcFrTuLyzmG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyPPzNeyo5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128 # Data points in a single batch\n",
        "embedding_size = 32 # Dimension of the embedding vector.\n",
        "# How many words to consider left and right.\n",
        "# Skip gram by design does not require to have all the context words in a given step\n",
        "# However, for CBOW that's a requirement, so we limit the window size\n",
        "window_size = 4\n",
        "\n",
        "# We pick a random validation set to sample nearest neighbors\n",
        "valid_size = 16 # Random set of words to evaluate similarity on.\n",
        "# We sample valid datapoints randomly from a large window without always being deterministic\n",
        "valid_window = 50\n",
        "\n",
        "# When selecting valid examples, we select some of the most frequent words as well as\n",
        "# some moderately rare words as well\n",
        "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
        "valid_examples = np.append(valid_examples,random.sample(range(1000, 1000+valid_window), valid_size),axis=0)\n",
        "\n",
        "num_sampled = 32 # Number of negative examples to sample."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Utvt1cqy3j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# Training input data (target word IDs). Note that it has 2*window_size columns\n",
        "train_dataset = tf.placeholder(tf.int32, shape=[batch_size,2*window_size])\n",
        "# Training input label data (context word IDs)\n",
        "train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
        "# Validation input data, we don't need a placeholder\n",
        "# as we have already defined the IDs of the words selected\n",
        "# as validation data\n",
        "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK3-DeGty3me",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0,dtype=tf.float32))\n",
        "\n",
        "# Softmax Weights and Biases\n",
        "softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],\n",
        "                 stddev=0.5 / math.sqrt(embedding_size),dtype=tf.float32))\n",
        "softmax_biases = tf.Variable(tf.random_uniform([vocabulary_size],0.0,0.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TBOwNVhy3rW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "31ef19ee-32f8-4ff2-97d3-d95e45abac85"
      },
      "source": [
        "stacked_embedings = None\n",
        "print('Defining %d embedding lookups representing each word in the context'%(2*window_size))\n",
        "for i in range(2*window_size):\n",
        "    embedding_i = tf.nn.embedding_lookup(embeddings, train_dataset[:,i])        \n",
        "    x_size,y_size = embedding_i.get_shape().as_list()\n",
        "    if stacked_embedings is None:\n",
        "        stacked_embedings = tf.reshape(embedding_i,[x_size,y_size,1])\n",
        "    else:\n",
        "        stacked_embedings = tf.concat(axis=2,values=[stacked_embedings,tf.reshape(embedding_i,[x_size,y_size,1])])\n",
        "\n",
        "assert stacked_embedings.get_shape().as_list()[2]==2*window_size\n",
        "print(\"Stacked embedding size: %s\"%stacked_embedings.get_shape().as_list())\n",
        "mean_embeddings =  tf.reduce_mean(stacked_embedings,2,keepdims=False)\n",
        "print(\"Reduced mean embedding size: %s\"%mean_embeddings.get_shape().as_list())\n",
        "\n",
        "# Compute the softmax loss, using a sample of the negative labels each time.\n",
        "# inputs are embeddings of the train words\n",
        "# with this loss we optimize weights, biases, embeddings\n",
        "loss = tf.reduce_mean(\n",
        "    tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=mean_embeddings,\n",
        "                           labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining 8 embedding lookups representing each word in the context\n",
            "Stacked embedding size: [128, 32, 8]\n",
            "Reduced mean embedding size: [128, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD8uLeKHy3tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwF_bdO-y3xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
        "normalized_embeddings = embeddings / norm\n",
        "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
        "similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCoNIBpk3IK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = tf.placeholder(tf.int32, shape=[batch_size],name='test_dataset')\n",
        "\n",
        "mean_batch_embedding = tf.reduce_mean(tf.nn.embedding_lookup(embeddings,test_labels),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdqJH8oKy3pB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9765f155-02d7-441d-98eb-ddf9d596e9d4"
      },
      "source": [
        "num_steps = 200001\n",
        "cbow_loss = []\n",
        "\n",
        "config=tf.ConfigProto(allow_soft_placement=True)\n",
        "# This is an important setting and with limited GPU memory,\n",
        "# not using this option might lead to the following error.\n",
        "# InternalError (see above for traceback): Blas GEMM launch failed : ...\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.Session(config=config) as session:\n",
        "    \n",
        "    # Initialize the variables in the graph\n",
        "    tf.global_variables_initializer().run()\n",
        "    print('Initialized')\n",
        "    \n",
        "    average_loss = 0\n",
        "    \n",
        "    # Train the Word2vec model for num_step iterations\n",
        "    for step in range(num_steps):\n",
        "        \n",
        "        # Generate a single batch of data\n",
        "        batch_data, batch_labels = generate_batch(data, batch_size, window_size)\n",
        "        \n",
        "        # Populate the feed_dict and run the optimizer (minimize loss)\n",
        "        # and compute the loss\n",
        "        feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n",
        "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
        "        \n",
        "        # Update the average loss variable\n",
        "        average_loss += l\n",
        "        \n",
        "        if (step+1) % 2000 == 0:\n",
        "            if step > 0:\n",
        "                average_loss = average_loss / 2000\n",
        "                # The average loss is an estimate of the loss over the last 2000 batches.\n",
        "            print('Average loss at step %d: %f' % (step+1, average_loss))\n",
        "            cbow_loss.append(average_loss)\n",
        "            average_loss = 0\n",
        "        \n",
        "        # Evaluating validation set word similarities\n",
        "       \n",
        "    \n",
        "    # Computing test documents embeddings by averaging word embeddings\n",
        "    \n",
        "    # We take batch_size*num_test_steps words from each document\n",
        "    # to compute document embeddings\n",
        "    num_test_steps = 100\n",
        "    \n",
        "    # Store document embeddings\n",
        "    # {document_id:embedding} format\n",
        "    document_embeddings = {}\n",
        "    print('Testing Phase (Compute document embeddings)')\n",
        "  \n",
        "      # For each test document compute document embeddings\n",
        "    for k,v in test_data.items():\n",
        "        print('\\tCalculating mean embedding for document ',k,' with ', num_test_steps, ' steps.')\n",
        "        test_data_index = 0\n",
        "        topic_mean_batch_embeddings = np.empty((num_test_steps,embedding_size),dtype=np.float32)\n",
        "        \n",
        "        # keep averaging mean word embeddings obtained for each step\n",
        "        for test_step in range(num_test_steps):\n",
        "            test_batch_labels = generate_test_batch(test_data[k],batch_size)\n",
        "            batch_mean = session.run(mean_batch_embedding,feed_dict={test_labels:test_batch_labels})\n",
        "            topic_mean_batch_embeddings[test_step,:] = batch_mean\n",
        "        document_embeddings[k] = np.mean(topic_mean_batch_embeddings,axis=0)\n",
        "        \n",
        "    word_embedding = session.run(embeddings)"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized\n",
            "Average loss at step 2000: 3.586534\n",
            "Average loss at step 4000: 3.181315\n",
            "Average loss at step 6000: 2.987666\n",
            "Average loss at step 8000: 2.827531\n",
            "Average loss at step 10000: 2.713530\n",
            "Average loss at step 12000: 2.636535\n",
            "Average loss at step 14000: 2.530674\n",
            "Average loss at step 16000: 2.443517\n",
            "Average loss at step 18000: 2.392001\n",
            "Average loss at step 20000: 2.332445\n",
            "Average loss at step 22000: 2.290571\n",
            "Average loss at step 24000: 2.256202\n",
            "Average loss at step 26000: 2.230088\n",
            "Average loss at step 28000: 2.164433\n",
            "Average loss at step 30000: 2.147199\n",
            "Average loss at step 32000: 2.143273\n",
            "Average loss at step 34000: 2.115013\n",
            "Average loss at step 36000: 2.088984\n",
            "Average loss at step 38000: 2.072071\n",
            "Average loss at step 40000: 2.064901\n",
            "Average loss at step 42000: 2.022371\n",
            "Average loss at step 44000: 2.026131\n",
            "Average loss at step 46000: 2.018900\n",
            "Average loss at step 48000: 1.996160\n",
            "Average loss at step 50000: 2.002527\n",
            "Average loss at step 52000: 1.984686\n",
            "Average loss at step 54000: 1.977134\n",
            "Average loss at step 56000: 1.938456\n",
            "Average loss at step 58000: 1.956604\n",
            "Average loss at step 60000: 1.945483\n",
            "Average loss at step 62000: 1.938835\n",
            "Average loss at step 64000: 1.936683\n",
            "Average loss at step 66000: 1.932495\n",
            "Average loss at step 68000: 1.930991\n",
            "Average loss at step 70000: 1.885147\n",
            "Average loss at step 72000: 1.900355\n",
            "Average loss at step 74000: 1.891552\n",
            "Average loss at step 76000: 1.895856\n",
            "Average loss at step 78000: 1.884899\n",
            "Average loss at step 80000: 1.887078\n",
            "Average loss at step 82000: 1.873876\n",
            "Average loss at step 84000: 1.869327\n",
            "Average loss at step 86000: 1.870267\n",
            "Average loss at step 88000: 1.870257\n",
            "Average loss at step 90000: 1.869685\n",
            "Average loss at step 92000: 1.862013\n",
            "Average loss at step 94000: 1.865869\n",
            "Average loss at step 96000: 1.845135\n",
            "Average loss at step 98000: 1.845682\n",
            "Average loss at step 100000: 1.851359\n",
            "Average loss at step 102000: 1.844474\n",
            "Average loss at step 104000: 1.833500\n",
            "Average loss at step 106000: 1.849875\n",
            "Average loss at step 108000: 1.837948\n",
            "Average loss at step 110000: 1.800712\n",
            "Average loss at step 112000: 1.812990\n",
            "Average loss at step 114000: 1.839024\n",
            "Average loss at step 116000: 1.830779\n",
            "Average loss at step 118000: 1.819036\n",
            "Average loss at step 120000: 1.819438\n",
            "Average loss at step 122000: 1.817436\n",
            "Average loss at step 124000: 1.796316\n",
            "Average loss at step 126000: 1.802979\n",
            "Average loss at step 128000: 1.806383\n",
            "Average loss at step 130000: 1.795137\n",
            "Average loss at step 132000: 1.800115\n",
            "Average loss at step 134000: 1.799349\n",
            "Average loss at step 136000: 1.797113\n",
            "Average loss at step 138000: 1.775621\n",
            "Average loss at step 140000: 1.804782\n",
            "Average loss at step 142000: 1.792708\n",
            "Average loss at step 144000: 1.783592\n",
            "Average loss at step 146000: 1.784047\n",
            "Average loss at step 148000: 1.785215\n",
            "Average loss at step 150000: 1.755863\n",
            "Average loss at step 152000: 1.764608\n",
            "Average loss at step 154000: 1.782765\n",
            "Average loss at step 156000: 1.783369\n",
            "Average loss at step 158000: 1.757647\n",
            "Average loss at step 160000: 1.771783\n",
            "Average loss at step 162000: 1.774732\n",
            "Average loss at step 164000: 1.742711\n",
            "Average loss at step 166000: 1.771457\n",
            "Average loss at step 168000: 1.765740\n",
            "Average loss at step 170000: 1.768665\n",
            "Average loss at step 172000: 1.769818\n",
            "Average loss at step 174000: 1.765816\n",
            "Average loss at step 176000: 1.764441\n",
            "Average loss at step 178000: 1.740238\n",
            "Average loss at step 180000: 1.754865\n",
            "Average loss at step 182000: 1.748496\n",
            "Average loss at step 184000: 1.752910\n",
            "Average loss at step 186000: 1.757436\n",
            "Average loss at step 188000: 1.755949\n",
            "Average loss at step 190000: 1.753242\n",
            "Average loss at step 192000: 1.724344\n",
            "Average loss at step 194000: 1.747850\n",
            "Average loss at step 196000: 1.745150\n",
            "Average loss at step 198000: 1.756261\n",
            "Average loss at step 200000: 1.750275\n",
            "Testing Phase (Compute document embeddings)\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-228.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-233.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-242.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-248.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-224.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-222.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-247.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-234.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-245.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-236.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-251.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-254.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-226.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-256.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-255.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-240.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-235.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-221.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-237.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-250.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-229.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-270.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-279.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-278.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-261.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-273.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-262.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-276.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-266.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-260.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-258.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-290.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-280.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-263.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-272.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-257.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-291.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-277.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-283.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-287.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-271.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-281.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-282.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-259.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-274.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-284.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-286.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-288.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-289.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-268.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-265.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-264.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-285.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-275.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-269.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-267.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-306.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-315.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-305.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-317.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-309.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-320.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-318.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-294.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-292.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-296.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-312.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-300.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-311.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-304.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-303.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-298.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-295.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-310.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-308.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-316.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-319.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-297.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-307.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-299.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-302.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-293.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-301.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-314.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-313.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-22.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-23.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-66.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-64.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-31.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-33.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-28.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-36.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-50.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-35.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-61.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-42.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-43.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-44.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-62.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-45.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-49.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-29.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-46.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-30.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-63.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-47.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-57.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-56.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-59.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-32.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-40.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-27.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-58.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-54.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-37.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-34.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-38.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-48.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-65.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-55.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-52.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-41.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-60.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-53.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-39.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-106.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-100.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-67.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-112.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-70.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-108.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-103.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-93.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-109.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-84.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-110.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-104.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-102.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-71.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-97.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-87.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-101.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-111.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-74.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-72.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-95.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-75.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-99.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-78.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-68.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-88.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-105.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-79.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-83.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-85.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-69.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-86.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-96.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-81.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-94.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-73.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-92.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-82.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-90.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-89.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-76.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-77.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-80.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-98.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-107.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-119.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-117.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-120.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-139.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-147.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-146.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-136.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-115.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-153.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-149.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-131.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-135.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-155.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-148.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-157.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-156.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-132.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-116.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-151.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-137.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-143.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-118.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-145.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-138.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-141.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-140.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-142.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-113.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-159.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-160.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-144.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-150.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-134.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-152.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-121.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-114.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-154.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-158.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-133.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-241.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-243.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-244.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-225.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-238.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-232.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-223.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-252.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-249.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-246.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-230.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-227.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-231.pdf  with  100  steps.\n",
            "\tCalculating mean embedding for document  Natural Language Processing with TensorFlow ( PDFDrive.com )-239.pdf  with  100  steps.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUfXHZ0ih_65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame.from_dict(document_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSrtsYuwivO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"document_embeddings.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYT41hr5bDXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n",
        "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAFEgeDn6cAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query = \"gradient clipping\"\n",
        "quer_list = []\n",
        "def filter_query(q):\n",
        "  tokens = q.split()\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "  table = str.maketrans('', '', string.punctuation)\n",
        "  stripped = [w.translate(table) for w in tokens]\n",
        "  words = [word for word in stripped if word.isalpha()]\n",
        "  words = [w for w in words if not w in alpha]\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  words = [w for w in words if not w in stop_words]\n",
        "  return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MowT3qFLNbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_list= filter_query(query)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsOd9Zg3LazP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "related_docs=[]\n",
        "\n",
        "for f in query_list:\n",
        "  a = worddic[f]\n",
        "  for x in a:\n",
        "    related_docs.append(x[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiDi2l0tQFjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_embedding =[]\n",
        "for f in query_list:\n",
        "  query_embedding.append(word_embedding1[dictionary[f]])\n",
        "\n",
        "query_embedding_mean = np.mean(np.array(query_embedding),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNnPTHxoMtcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "related_docs_unique = list(set(related_docs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smDz0J-vRhdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def similar_func(related_docs_unique,query_embedding_mean):                               \n",
        "\n",
        "  similarity={}\n",
        "\n",
        "  for f in range(len(related_docs_unique)):\n",
        "    score= get_cosine_similarity(document_embeddings[related_docs_unique[f]],query_embedding_mean)\n",
        "    similarity[related_docs_unique[f]]=score\n",
        "\n",
        "  similarity_sort=sorted(similarity.items(), key=operator.itemgetter(1),reverse=True)\n",
        "  return(similarity_sort)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCja-kcCZPc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "84d766ce-6e34-4ab8-a054-391aab698e91"
      },
      "source": [
        "similar_func(related_docs_unique,query_embedding_mean)"
      ],
      "execution_count": 436,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Natural Language Processing with TensorFlow ( PDFDrive.com )-240.pdf',\n",
              "  0.6701666),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-263.pdf',\n",
              "  0.58353657),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-241.pdf',\n",
              "  0.5826148),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-239.pdf',\n",
              "  0.53367114),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-289.pdf',\n",
              "  0.5116844),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-238.pdf',\n",
              "  0.49216157),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-225.pdf',\n",
              "  0.38376698),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-226.pdf',\n",
              "  0.34090504),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-44.pdf',\n",
              "  0.33073175),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-227.pdf',\n",
              "  0.31529427),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-252.pdf',\n",
              "  0.25295624),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-257.pdf',\n",
              "  0.25135052),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-80.pdf',\n",
              "  0.24116237),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-37.pdf',\n",
              "  0.24065158),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-221.pdf',\n",
              "  0.23645465),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-312.pdf',\n",
              "  0.1864441),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-254.pdf',\n",
              "  0.16702482),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-36.pdf',\n",
              "  0.1313811),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-141.pdf',\n",
              "  0.096309796),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-137.pdf',\n",
              "  -0.018787682),\n",
              " ('Natural Language Processing with TensorFlow ( PDFDrive.com )-88.pdf',\n",
              "  -0.03395506)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 436
        }
      ]
    }
  ]
}